{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "\n",
    "from IPython.display import Markdown as md\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "#tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\rodri\\\\My GIT Projects\\\\Challenges-Requirements-Analytical-Projects\\\\notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data/raw/real_world_covid_mask_images/without_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-aa94a0a434b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mload_full_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/raw/real_world_covid_mask_images/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-aa94a0a434b6>\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(data_dir)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# percorre todas as imagens presentes no diretório, converte para grey_sacale e faz o resizing das imagens.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mimage_read\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mimage_resized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_read\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data/raw/real_world_covid_mask_images/without_mask'"
     ]
    }
   ],
   "source": [
    "image_size = 256\n",
    "labels = ['without_mask', 'with_mask']\n",
    "\n",
    "def get_data(data_dir):\n",
    "        \n",
    "    images = []\n",
    "    \n",
    "# cria uma lista com o index de cada label com base no nome da raíz do diretório informado.\n",
    "    for label in labels:\n",
    "        dir = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        \n",
    "# percorre todas as imagens presentes no diretório, converte para grey_sacale e faz o resizing das imagens.\n",
    "        for image in os.listdir(dir):    \n",
    "            image_read = cv.imread(os.path.join(dir,image), cv.IMREAD_GRAYSCALE)\n",
    "            image_resized = cv.resize(image_read, (image_size, image_size))\n",
    "            images.append([image_resized, class_num])\n",
    "\n",
    "    return np.array(images)\n",
    "\n",
    "load_full_dataset = get_data('../data/raw/real_world_covid_mask_images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_count = np.count_nonzero(load_full_dataset[:,1] == 1)\n",
    "no_mask_count = np.count_nonzero(load_full_dataset[:,1] == 0)\n",
    "\n",
    "print('Dataset original\\n\\n', len(load_full_dataset),\n",
    "      'imagens no dataset com o tamanho', load_full_dataset[1,0].shape,\n",
    "      '\\n\\nProporção',\n",
    "      '\\nSem máscara:\\t', no_mask_count,\n",
    "      '\\nCom máscara:\\t', mask_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dataset = load_full_dataset[load_full_dataset[:,1]==1]\n",
    "no_mask_dataset = load_full_dataset[load_full_dataset[:,1]==0]\n",
    "\n",
    "random_positions = np.random.choice(no_mask_count, replace=False, size=mask_count)\n",
    "\n",
    "shuffled_no_mask_dataset = no_mask_dataset[random_positions,]\n",
    "\n",
    "# # Reduce dataset size for testing purposes\n",
    "# mask_dataset = mask_dataset[0:200,]\n",
    "# shuffled_no_mask_dataset = shuffled_no_mask_dataset[0:200,]\n",
    "\n",
    "# New loaded set (balanced) with shuffled no-mask dataset\n",
    "load_full_dataset = np.concatenate((mask_dataset, shuffled_no_mask_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_count = np.count_nonzero(load_full_dataset[:,1] == 1)\n",
    "no_mask_count = np.count_nonzero(load_full_dataset[:,1] == 0)\n",
    "\n",
    "print('Dataset rebalanceado (com seleção aleatória da classe majoritária)\\n\\n', len(load_full_dataset),\n",
    "      'imagens no dataset com o tamanho', load_full_dataset[1,0].shape,\n",
    "      '\\n\\nProporção',\n",
    "      '\\nSem máscara:\\t', no_mask_count,\n",
    "      '\\nCom máscara:\\t', mask_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "fig = plt.figure(figsize = (12, 12))\n",
    "columns = 4\n",
    "rows = 3\n",
    "\n",
    "randomlist = []\n",
    "\n",
    "for i in range(0, int((columns * rows)/2)):\n",
    "    n = np.random.randint(0, np.count_nonzero(load_full_dataset[:,1] == 0))\n",
    "    randomlist.append(n)\n",
    "    \n",
    "for i in range(0, int((columns * rows)/2)):\n",
    "    n = np.random.randint(np.count_nonzero(load_full_dataset[:,1] == 0), len(load_full_dataset))\n",
    "    randomlist.append(n)\n",
    "    \n",
    "for i in range(1, columns * rows + 1):\n",
    "    rnd = np.random.randint(0, len(load_full_dataset))\n",
    "    img = load_full_dataset[randomlist[i-1]][0]  \n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.title(labels[load_full_dataset[randomlist[i-1]][1]])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = []\n",
    "y_labels = []\n",
    "\n",
    "for feature, label in load_full_dataset:\n",
    "    x_features.append(feature)\n",
    "    y_labels.append(label)\n",
    "    \n",
    "del load_full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features = np.array(x_features).reshape(-1, image_size, image_size, 1)\n",
    "y_labels = np.array(y_labels)\n",
    "y_labels = np.expand_dims(y_labels, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_features, \n",
    "                                                    y_labels,\n",
    "                                                    stratify = y_labels,\n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 2)\n",
    "\n",
    "del x_features, y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTensor de features de treinamento:\\t', x_train.shape, \n",
    "      '\\nImagens:\\t', len(x_train), \n",
    "      '\\nSem máscara:\\t', np.count_nonzero(y_train == 0), \n",
    "      '\\nCom máscara:\\t', np.count_nonzero(y_train == 1))\n",
    "\n",
    "print('\\nTensor de labels de treinamento:\\t', y_train.shape, \n",
    "      '\\nQuantidade:\\t', len(y_train),\n",
    "      '\\nSem máscara:\\t', np.count_nonzero(y_train == 0), \n",
    "      '\\nCom máscara:\\t', np.count_nonzero(y_train == 1))\n",
    "\n",
    "print('\\nTensor de features de teste:\\t\\t', x_test.shape, \n",
    "      '\\nImagens:\\t', len(x_test),\n",
    "      '\\nSem máscara:\\t', np.count_nonzero(y_test == 0), \n",
    "      '\\nCom máscara:\\t', np.count_nonzero(y_test == 1))\n",
    "\n",
    "print('\\nTensor de labels de teste:\\t\\t', y_test.shape, \n",
    "      '\\nQuantidade:\\t', len(y_test),\n",
    "      '\\nSem máscara:\\t', np.count_nonzero(y_test == 0), \n",
    "      '\\nCom máscara:\\t', np.count_nonzero(y_test == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test  = x_test  / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Input(x_train.shape[1:], name=\"entrada\")\n",
    "a = Flatten(name=\"achatamento\")(i)\n",
    "a = Dense(512, activation = 'relu', name=\"densa1\")(a)\n",
    "a = Dropout(0.4, name=\"reducao1\")(a)\n",
    "a = Dense(512, activation = 'relu', name=\"densa2\")(a)\n",
    "a = Dropout(0.3, name=\"reducao2\")(a)\n",
    "a = Dense(512, activation = 'relu', name=\"densa3\")(a)\n",
    "a = Dropout(0.1, name=\"reducao3\")(a)\n",
    "a = Dense(1, activation = 'sigmoid', name=\"previsao\")(a)\n",
    "\n",
    "model_NN = Model(i,a, name='NN')\n",
    "\n",
    "model_NN.compile(optimizer = 'SGD',\n",
    "                 loss = \"binary_crossentropy\",\n",
    "                 metrics = [\"accuracy\"])\n",
    "\n",
    "#model_NN.compile(optimizer = tf.keras.optimizers.SGD(),\n",
    "#                 loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "#                 metrics = [tf.keras.metrics.Accuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Input(x_train.shape[1:], name=\"entrada\")\n",
    "b = Conv2D(32, (3,3), activation ='relu', padding = 'same', name=\"convolucao2d1\")(i)\n",
    "b = BatchNormalization(name=\"normalizacao1\")(b)\n",
    "b = Conv2D(32, (3,3), activation ='relu', padding = 'same', name=\"convolucao2d2\")(b)\n",
    "b = BatchNormalization(name=\"normalizacao2\")(b)\n",
    "b = MaxPooling2D(2,2, name=\"acumulacao1\")(b)\n",
    "b = Conv2D(64, (3,3), activation ='relu', padding = 'same', name=\"convolucao2d3\")(b)\n",
    "b = BatchNormalization(name=\"normalizacao3\")(b)\n",
    "b = Conv2D(64, (3,3), activation ='relu', padding = 'same', name=\"convolucao2d4\")(b)\n",
    "b = BatchNormalization(name=\"normalizacao4\")(b)\n",
    "b = MaxPooling2D(2,2, name=\"acumulacao2\")(b)\n",
    "b = Conv2D(128, (3,3), activation ='relu', padding = 'same', name=\"convolucao2d5\")(b)\n",
    "b = BatchNormalization(name=\"normalizacao5\")(b)\n",
    "b = Conv2D(128, (3,3), activation ='relu', padding = 'same', name=\"convolucao2d6\")(b)\n",
    "b = BatchNormalization(name=\"normalizacao6\")(b)\n",
    "b = MaxPooling2D(2,2, name=\"acumulacao3\")(b)\n",
    "b = Conv2D(256, (3,3), activation ='relu', padding = 'same', name=\"convolucao2d7\")(b)\n",
    "b = BatchNormalization(name=\"normalizacao7\")(b)\n",
    "b = Conv2D(256, (3,3), activation ='relu', padding = 'same', name=\"convolucao2d8\")(b)\n",
    "b = BatchNormalization(name=\"normalizacao8\")(b)\n",
    "b = MaxPooling2D(2,2, name=\"acumulacao4\")(b)\n",
    "b = Flatten(name=\"achatamento\")(b)\n",
    "b = Dense(512, activation = 'relu', name=\"densa1\")(b)\n",
    "b = Dropout(0.4, name=\"reducao1\")(b)\n",
    "b = Dense(512, activation = 'relu', name=\"densa2\")(b)\n",
    "b = Dropout(0.3, name=\"reducao2\")(b)\n",
    "b = Dense(512, activation = 'relu', name=\"densa3\")(b)\n",
    "b = Dropout(0.1, name=\"reducao3\")(b)\n",
    "b = Dense(1, activation = 'sigmoid', name=\"previsao\")(b)\n",
    "\n",
    "model_CNN = Model(i, b, name='CNN')\n",
    "\n",
    "model_CNN.compile(optimizer = 'SGD',\n",
    "                  loss = \"binary_crossentropy\",\n",
    "                  metrics = [\"accuracy\"])\n",
    "\n",
    "#model_CNN.compile(optimizer = tf.keras.optimizers.SGD(),\n",
    "#                 loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "#                  metrics = [tf.keras.metrics.Accuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_gen = ImageDataGenerator(rotation_range = 10,\n",
    "                               horizontal_flip = True,\n",
    "                               width_shift_range = 0.1,\n",
    "                               height_shift_range = 0.1,\n",
    "                               rescale = 1.,\n",
    "                               zoom_range = 0.2,\n",
    "                               fill_mode = 'nearest',\n",
    "                               cval = 0)\n",
    "\n",
    "train_generator_NN = train_gen.flow(x_train, y_train, batch_size)\n",
    "train_generator_CNN = train_gen.flow(x_train, y_train, batch_size)\n",
    "\n",
    "steps_per_epoch = x_train.shape[0] // batch_size\n",
    "\n",
    "checkpoint_NN = ModelCheckpoint('../models/model_NN.h5', \n",
    "                                monitor = 'val_loss', \n",
    "                                verbose = 0, \n",
    "                                save_best_only = True, \n",
    "                                mode = 'auto')\n",
    "\n",
    "checkpoint_CNN = ModelCheckpoint('../models/model_CNN.h5', \n",
    "                                 monitor = 'val_loss', \n",
    "                                 verbose = 0, \n",
    "                                 save_best_only = True, \n",
    "                                 mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10 # Reduce number of epochs for testing purposes\n",
    "\n",
    "history_NN = model_NN.fit(train_generator_NN, \n",
    "                          validation_data = (x_test, y_test), \n",
    "                          steps_per_epoch = steps_per_epoch, \n",
    "                          epochs = epochs,\n",
    "                          callbacks = [checkpoint_NN],\n",
    "                          verbose = 2)\n",
    "\n",
    "history_CNN = model_CNN.fit(train_generator_CNN, \n",
    "                            validation_data = (x_test, y_test), \n",
    "                            steps_per_epoch = steps_per_epoch, \n",
    "                            epochs = epochs,\n",
    "                            callbacks = [checkpoint_CNN],\n",
    "                            verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NN = tf.keras.models.load_model('../models/model_NN.h5')\n",
    "model_CNN = tf.keras.models.load_model('../models/model_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_hist(model_history, fig_title):\n",
    "\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "    fig = plt.figure(figsize = (16, 4))\n",
    "    columns = 2\n",
    "    rows = 1\n",
    "\n",
    "    fig.suptitle(fig_title, fontsize = 20, y = 1.08)\n",
    "    fig.add_subplot(rows, columns, 1)\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    #plt.ylim(0.6, 1)\n",
    "    \n",
    "    plt.plot(model_history.history['acc'], \n",
    "             color='green', \n",
    "             label = 'Train Accuracy')\n",
    "\n",
    "    plt.plot(model_history.history['val_acc'], \n",
    "             color='red', \n",
    "             label = 'Test Accuracy', \n",
    "             linestyle='dashed')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    fig.add_subplot(rows, columns, 2)\n",
    "\n",
    "    plt.title('Loss')\n",
    "    plt.plot(model_history.history['loss'], \n",
    "             color='green', \n",
    "             label = 'Train Loss')\n",
    "\n",
    "    plt.plot(model_history.history['val_loss'], \n",
    "             color='red', \n",
    "             label = 'Test Loss', \n",
    "             linestyle='dashed')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plot_accuracy_hist(history_NN, 'Neural Network')\n",
    "plot_accuracy_hist(history_CNN, 'Convolutional Neural Network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "def plot_confusion_mtx(model, x_test, plot_tittle):\n",
    "    pred_prob = model.predict(x_test, batch_size = 8)\n",
    "    pred = np.where(pred_prob > 0.5, 1,0)\n",
    "\n",
    "    CM = confusion_matrix(y_test, pred)\n",
    "\n",
    "    plot_confusion_matrix(conf_mat = CM, figsize = (16, 8))\n",
    "    plt.title(plot_tittle)\n",
    "    plt.xticks(range(2), labels)\n",
    "    plt.yticks(range(2), labels)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_mtx(model_NN, x_test, 'Neural Network')\n",
    "plot_confusion_mtx(model_CNN, x_test, 'Convolutional Neural Network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_NN  = model_NN.predict(x_test, batch_size = 8)\n",
    "pred_prob_CNN = model_CNN.predict(x_test, batch_size = 8)\n",
    "\n",
    "pred_NN  = np.where(pred_prob_NN > 0.5, 1,0)\n",
    "pred_CNN = np.where(pred_prob_CNN > 0.5, 1,0)\n",
    "\n",
    "NN_fpr, NN_tpr, _ = roc_curve(y_test, pred_prob_NN)\n",
    "NN_roc_auc = auc(NN_fpr, NN_tpr)\n",
    "\n",
    "CNN_fpr, CNN_tpr, _ = roc_curve(y_test, pred_prob_CNN)\n",
    "CNN_roc_auc = auc(CNN_fpr, CNN_tpr)\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "fig = plt.figure(figsize = (8, 6))\n",
    "\n",
    "lw = 2\n",
    "plt.plot(CNN_fpr,\n",
    "         CNN_tpr, \n",
    "         color = 'darkorange',\n",
    "         lw = lw, \n",
    "         label = 'CNN - ROC curve (area = %0.2f)' % CNN_roc_auc)\n",
    "\n",
    "plt.plot(NN_fpr,\n",
    "         NN_tpr, \n",
    "         color = 'grey',\n",
    "         lw = lw, \n",
    "         label = '  NN - ROC curve (area = %0.2f)' % NN_roc_auc)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \n",
    "         color = 'navy', \n",
    "         lw = lw, \n",
    "         linestyle = '--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc = \"lower right\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Classification Report - Neural Network')\n",
    "print(classification_report(y_test, pred_NN))\n",
    "\n",
    "print('\\nClassification Report - Convolutional Neural Network')\n",
    "print(classification_report(y_test, pred_CNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
